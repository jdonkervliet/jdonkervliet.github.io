<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://jdonkervliet.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://jdonkervliet.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-09-06T12:24:09+00:00</updated><id>https://jdonkervliet.github.io/feed.xml</id><title type="html">blank</title><subtitle>Jesse&apos;s personal Web page </subtitle><entry><title type="html">Measuring the Metaverse: accepted at HotCloudPerf 2023</title><link href="https://jdonkervliet.github.io/blog/2023/measuring-the-metaverse-hotcloudperf/" rel="alternate" type="text/html" title="Measuring the Metaverse: accepted at HotCloudPerf 2023"/><published>2023-02-17T00:00:00+00:00</published><updated>2023-02-17T00:00:00+00:00</updated><id>https://jdonkervliet.github.io/blog/2023/measuring-the-metaverse-hotcloudperf</id><content type="html" xml:base="https://jdonkervliet.github.io/blog/2023/measuring-the-metaverse-hotcloudperf/"><![CDATA[<p>I’m proud to announce our work ‘‘Can My WiFi Handle the Metaverse? A Performance Evaluation Of Meta’s Flagship Virtual Reality Hardware’’ has been accepted at <a href="https://hotcloudperf.spec.org/">HotCloudPerf 2023</a>!</p> <p>In this work, we design and conduct experiments using the Meta Quest Pro VR headset to determine if modern WiFi networks provide sufficiently good performance to support the much-anticipated metaverse, and obtain surprising results.</p> <p>The full paper is available <a href="https://atlarge-research.com/pdfs/2023-jansen-measuringthemetaverse.pdf">here</a>. All our artifacts and data are available <a href="https://github.com/atlarge-research/measuring-the-metaverse">here</a>.</p> <p>Abstract:</p> <blockquote> <p>Extending human societies into virtual space through the construction of a metaverse has been a long-term challenge in both industry and academia. Achieving this challenge is now closer than ever due to advances in computer systems, facilitating large-scale online platforms such as Minecraft and Roblox that fulfill an increasing number of societal needs, and extended reality (XR) hardware, which provides users with state-of-the-art immersive experiences. For a metaverse to succeed, we argue that all involved systems must provide consistently good performance. However, there is a lack of knowledge on the performance characteristics of extended reality devices. In this paper, we address this gap and focus on extended- and virtual-reality hardware. We synthesize a user-centered system model that models common deployments of XR hardware and their trade-offs. Based on this model, we design and conduct real-world experiments with Meta’s flagship virtual reality device, the Quest Pro. We highlight two surprising results from our findings which show that (i) under our workload, the battery drains 15% faster when using wireless offloading compared to local execution, and (ii) the outdated 2.4 GHz WiFi4 gives surprisingly good performance, with 99% of samples achieving a frame rate of at least 65 Hz, compared to the 72 Hz performance target. Our experimental setup and data are available at https://github.com/atlarge-research/measuring-the-metaverse.</p> </blockquote>]]></content><author><name></name></author><category term="research"/><category term="news"/><category term="article"/><summary type="html"><![CDATA[I’m proud to announce our work ‘‘Can My WiFi Handle the Metaverse? A Performance Evaluation Of Meta’s Flagship Virtual Reality Hardware’’ has been accepted at HotCloudPerf 2023!]]></summary></entry><entry><title type="html">VU Amsterdam Open Day — Computer Science Bachelor</title><link href="https://jdonkervliet.github.io/blog/2023/vu-cs-bsc-open-day/" rel="alternate" type="text/html" title="VU Amsterdam Open Day — Computer Science Bachelor"/><published>2023-02-11T00:00:00+00:00</published><updated>2023-02-11T00:00:00+00:00</updated><id>https://jdonkervliet.github.io/blog/2023/vu-cs-bsc-open-day</id><content type="html" xml:base="https://jdonkervliet.github.io/blog/2023/vu-cs-bsc-open-day/"><![CDATA[<p>I represented Vrije Universiteit (VU) Amsterdam’s Computer Science department this weekend at the virtual open day. It was great to see interest from people all over the world for studying computer science at VU. I hope to see you in Amsterdam!</p> <p><img src="/images/open-day.png" alt="VU Open Day Computer Science Bachelor"/></p>]]></content><author><name></name></author><category term="news"/><summary type="html"><![CDATA[I represented Vrije Universiteit (VU) Amsterdam’s Computer Science department this weekend at the virtual open day. It was great to see interest from people all over the world for studying computer science at VU. I hope to see you in Amsterdam!]]></summary></entry><entry><title type="html">Meterstick accepted at ICPE 2023</title><link href="https://jdonkervliet.github.io/blog/2023/meterstick-icpe/" rel="alternate" type="text/html" title="Meterstick accepted at ICPE 2023"/><published>2023-02-01T00:00:00+00:00</published><updated>2023-02-01T00:00:00+00:00</updated><id>https://jdonkervliet.github.io/blog/2023/meterstick-icpe</id><content type="html" xml:base="https://jdonkervliet.github.io/blog/2023/meterstick-icpe/"><![CDATA[<p>I’m proud to announce our work ‘‘Meterstick: Benchmarking Performance Variability in Cloud and Self-hosted Minecraft-like Games’’ has been accepted at <a href="https://icpe2023.spec.org/">ICPE 2023</a>!</p> <p>The work is led by <a href="https://www.linkedin.com/in/jerrit-eickhoff/">Jerrit Eickhoff</a>, who completed this work over the course of his bachelor’s honours and bachelor thesis projects at VU Amsterdam. Well done, Jerrit!</p> <p>Meterstick abstract:</p> <blockquote> <p>Due to increasing popularity and strict performance requirements, online games have become a cloud-based and self-hosted work-load of interest for the performance engineering community. One of the most popular types of online games is the Minecraft-like Game (MLG), in which players can terraform the environment. The most popular MLG, Minecraft, provides not only entertainment, but also educational support and social interaction, to over 130 million people world-wide. MLGs currently support their many players by replicating isolated instances that support each only up to a few hundred players under favorable conditions. In practice, as we show here, the real upper limit of supported players can be much lower. In this work, we posit that performance variability is a key cause for the lack of scalability in MLGs, investigate experimentally causes of performance variability, and derive actionable insights. We propose an operational model for MLGs, which extends the state-of-the-art with essential aspects, e.g., through the consideration of environment-based workloads, which are sizable workload components that do not depend on player input (once set in action). Starting from this model, we design the first benchmark that focuses on MLG performance variability, defining specialized workloads, metrics, and processes. We conduct real-world benchmarking of MLGs, both cloud-based and self-hosted. We find environment-based workloads and cloud deployment are significant sources of performance variability: peak-latency degrades sharply to 20.7 times the arithmetic mean, and exceeds by a factor of 7.4 the performance requirements. We derive actionable insights for game-developers, game-operators, and other stakeholders to tame performance variability.</p> </blockquote> <p>If you want to know more, check out <a href="https://atlarge-research.com/pdfs/2023-jeickhoff-Meterstick-ICPE2023.pdf">the full paper</a> and let’s have a chat at ICPE in Coimbra!</p>]]></content><author><name></name></author><category term="research"/><category term="news"/><category term="article"/><summary type="html"><![CDATA[I’m proud to announce our work ‘‘Meterstick: Benchmarking Performance Variability in Cloud and Self-hosted Minecraft-like Games’’ has been accepted at ICPE 2023!]]></summary></entry><entry><title type="html">Including the Git Commit Hash in a Runnable Jar</title><link href="https://jdonkervliet.github.io/blog/2021/git-version-in-jar/" rel="alternate" type="text/html" title="Including the Git Commit Hash in a Runnable Jar"/><published>2021-10-22T00:00:00+00:00</published><updated>2021-10-22T00:00:00+00:00</updated><id>https://jdonkervliet.github.io/blog/2021/git-version-in-jar</id><content type="html" xml:base="https://jdonkervliet.github.io/blog/2021/git-version-in-jar/"><![CDATA[<p>Because implementing your system and running experiments with it can happen concurrently, it is important to keep track of which version of your code you used for which experiment. With a fast development cycle, that can get tricky.</p> <p>Fortunately, this problem is easy to solve when working with Maven. Using the <code class="language-plaintext highlighter-rouge">buildnumber-maven-plugin</code>, you can automatically add the current git commit hash to your JAR file. If you keep your JAR around, you can always tell from which commit it was built.</p> <p>First declare the plugin in your <code class="language-plaintext highlighter-rouge">pom.xml</code>:</p> <div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">&lt;!-- Version control information used by the buildnumber-maven-plugin --&gt;</span>
<span class="nt">&lt;scm&gt;</span>
    <span class="nt">&lt;developerConnection&gt;</span>scm:git:git@github.com:username/repo.git<span class="nt">&lt;/developerConnection&gt;</span>
    <span class="nt">&lt;url&gt;</span>https://github.com/username/repo<span class="nt">&lt;/url&gt;</span>
<span class="nt">&lt;/scm&gt;</span>

<span class="nt">&lt;build&gt;</span>
    <span class="nt">&lt;plugins&gt;</span>
        <span class="c">&lt;!-- Plugin that lets us package the git commit hash in the executable JAR --&gt;</span>
        <span class="nt">&lt;plugin&gt;</span>
            <span class="nt">&lt;groupId&gt;</span>org.codehaus.mojo<span class="nt">&lt;/groupId&gt;</span>
            <span class="nt">&lt;artifactId&gt;</span>buildnumber-maven-plugin<span class="nt">&lt;/artifactId&gt;</span>
            <span class="nt">&lt;version&gt;</span>1.4<span class="nt">&lt;/version&gt;</span>
            <span class="nt">&lt;executions&gt;</span>
                <span class="nt">&lt;execution&gt;</span>
                    <span class="nt">&lt;phase&gt;</span>validate<span class="nt">&lt;/phase&gt;</span>
                    <span class="nt">&lt;goals&gt;</span>
                        <span class="nt">&lt;goal&gt;</span>create<span class="nt">&lt;/goal&gt;</span>
                    <span class="nt">&lt;/goals&gt;</span>
                    <span class="nt">&lt;configuration&gt;</span>
                        <span class="nt">&lt;doCheck&gt;</span>true<span class="nt">&lt;/doCheck&gt;</span>
                    <span class="nt">&lt;/configuration&gt;</span>
                <span class="nt">&lt;/execution&gt;</span>
            <span class="nt">&lt;/executions&gt;</span>
        <span class="nt">&lt;/plugin&gt;</span>
    <span class="nt">&lt;/plugins&gt;</span>
<span class="nt">&lt;/build&gt;</span>
</code></pre></div></div> <p>The plugin requires the <code class="language-plaintext highlighter-rouge">scm</code> tag, which tells it which source control management (SCM) tool you are using and where to find the code repository. The execution configures the plugin to add the commit hash to the JAR during Maven’s validate phase.</p> <p>The <code class="language-plaintext highlighter-rouge">doCheck</code> parameter checks that there are no uncommitted changes in the repository. This is important, because you identify the JAR based on the commit hash. If you can build the code with uncommitted changes, these builds are no longer unique. If you do need to build your project without committing, you can use the flag <code class="language-plaintext highlighter-rouge">-Dmaven.buildNumber.doCheck=false</code>.</p> <p>Now, use the following code to store the commit hash in your JAR file. The <code class="language-plaintext highlighter-rouge">buildnumber</code> plugin makes the commit hash available as <code class="language-plaintext highlighter-rouge">${buildNumber}</code> in your POM file, which you can pass to the <code class="language-plaintext highlighter-rouge">maven-jar-plugin</code> to add the value to your manifest file.</p> <div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">&lt;!-- A plugin that places the buildNumber (i.e., git hash) in the generated JAR archive --&gt;</span>
<span class="nt">&lt;plugin&gt;</span>
    <span class="nt">&lt;groupId&gt;</span>org.apache.maven.plugins<span class="nt">&lt;/groupId&gt;</span>
    <span class="nt">&lt;artifactId&gt;</span>maven-jar-plugin<span class="nt">&lt;/artifactId&gt;</span>
    <span class="nt">&lt;version&gt;</span>3.2.0<span class="nt">&lt;/version&gt;</span>
    <span class="nt">&lt;configuration&gt;</span>
        <span class="nt">&lt;archive&gt;</span>
            <span class="nt">&lt;manifest&gt;</span>
                <span class="nt">&lt;addDefaultImplementationEntries&gt;</span>true<span class="nt">&lt;/addDefaultImplementationEntries&gt;</span>
            <span class="nt">&lt;/manifest&gt;</span>
            <span class="nt">&lt;manifestEntries&gt;</span>
                <span class="nt">&lt;Implementation-Build&gt;</span>${buildNumber}<span class="nt">&lt;/Implementation-Build&gt;</span>
            <span class="nt">&lt;/manifestEntries&gt;</span>
        <span class="nt">&lt;/archive&gt;</span>
    <span class="nt">&lt;/configuration&gt;</span>
<span class="nt">&lt;/plugin&gt;</span>
</code></pre></div></div> <p>The result:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>unzip <span class="nt">-p</span> target/build-dev.jar META-INF/MANIFEST.MF
Manifest-Version: 1.0
Created-By: Maven Jar Plugin 3.2.0
Build-Jdk-Spec: 11
Implementation-Title: dist
Implementation-Version: dev
Implementation-Build: 09fcf03c5037fa4ee7699a112f77f70f00d435da
</code></pre></div></div> <p>This JAR file was built from commit <code class="language-plaintext highlighter-rouge">09fcf03c5037fa4ee7699a112f77f70f00d435da</code>!</p>]]></content><author><name></name></author><category term="software-engineering"/><category term="maven"/><category term="java"/><summary type="html"><![CDATA[Because implementing your system and running experiments with it can happen concurrently, it is important to keep track of which version of your code you used for which experiment. With a fast development cycle, that can get tricky.]]></summary></entry><entry><title type="html">Setting up a Nexus Artifact Repository</title><link href="https://jdonkervliet.github.io/blog/2020/opencraft-nexus/" rel="alternate" type="text/html" title="Setting up a Nexus Artifact Repository"/><published>2020-08-31T00:00:00+00:00</published><updated>2020-08-31T00:00:00+00:00</updated><id>https://jdonkervliet.github.io/blog/2020/opencraft-nexus</id><content type="html" xml:base="https://jdonkervliet.github.io/blog/2020/opencraft-nexus/"><![CDATA[<p>After struggling with sharing Maven artifacts for longer than I want to admit, I finally set up a dedicated artifact repository for Opencraft.</p> <p>For my PhD, I work on a research project called <a href="https://atlarge-research.com/opencraft/">Opencraft</a>. The goal of Opencraft is to discover and evaluate novel scalability techniques for large-scale online games. As part of this project, we design and develop our own large-scale Minecraft-like game, also called Opencraft.</p> <p>Opencraft has tens of software dependencies, which are obtained from external sources by <a href="https://maven.apache.org/">Maven</a>. Although this works well for the majority of the dependencies, there a few dependencies that are more difficult to manage. Specifically, these dependencies introduce two challenges:</p> <ol> <li>They exclusively use SNAPSHOT versions, no releases.</li> <li>Only the <em>x</em>-most recent versions of these SNAPSHOTS are available from their artifact repository.</li> </ol> <p><span id="requirements"> Opencraft is a research project, which means many students and researchers use it to conduct their experiments. This introduces two important requirements: </span></p> <ol> <li>We can compile previous versions of Opencraft years after they have been used for experiments.</li> <li>We support reproducible builds. The Opencraft binary only changes if its own source code changes.</li> </ol> <p>These requirements mean that dependencies must be permanently available, in case an older version of the code needs to be compiled (Requirement 1). It also means that, once a SNAPSHOT version of a dependency is used to compile Opencraft, that SNAPSHOT may no longer change (Requirement 2).</p> <p>It turns out that we can meet both requirements by using our own artifact repository. The remainder of this post discusses how I set up such an artifact repository for Opencraft.</p> <hr/> <h1 id="setup">Setup</h1> <p>My setup consists of a Docker Compose file that defines two services: a Sonatype Nexus 3, and an NGINX reverse proxy. To set up these services correctly, we need to configure NGINX to use HTTPS and function as a reverse proxy for Nexus.</p> <h2 id="nginx">NGINX</h2> <p>In hindsight, the configuration of the NGINX web server proved to be the majority of the work. I was happy to find a tutorial for my use-case at <a href="https://www.freecodecamp.org/news/docker-nginx-letsencrypt-easy-secure-reverse-proxy-40165ba3aee2/">https://www.freecodecamp.org/news/docker-nginx-letsencrypt-easy-secure-reverse-proxy-40165ba3aee2/</a>. The steps shown in this section closely follow the ones from this tutorial.</p> <p>The Docker NGINX image comes with a bunch of useful configuration files out of the box. Unfortunately, these configuration files will no longer be accessible after mounting a host directory at the same location. Therefore, we first copy the default NGINX configuration to the host by creating an NGINX container and copying its config files.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Get nginx's default configuration to use as a template.
mkdir nginx
cd nginx
docker run -d --name nginx nginx
docker cp nginx:/etc/nginx/ .
docker container stop nginx
docker container rm nginx
</code></pre></div></div> <p>Mounting a host directory in the Docker container allows me to keep the NGINX configuration on the host’s file system. This approach has two clear benefits. First, it enables updating NGINX without reconfiguration. Second, it enables me to share the NGINX config files with team members using version control.</p> <p>Next, we remove an unneeded configuration file, and create two directories to create and enable <em>sites</em>. Each site is a service with a user-accessible web interface. Currently, we only have one site: the Nexus. This means that creating the two directories is not necessary for our current setup, but it allows me to easily add more sites later.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cd nginx/conf.d
rm default.conf
mkdir sites-available sites-enabled
</code></pre></div></div> <p>Creating these directories requires a slight change in <code class="language-plaintext highlighter-rouge">nginx.conf</code>: <code class="language-plaintext highlighter-rouge">include /etc/nginx/conf.d/*.conf;</code> becomes <code class="language-plaintext highlighter-rouge">include /etc/nginx/conf.d/sites-enabled/*.conf;</code></p> <p>Each site gets its own configuration file. In this case, that means creating a configuration file at <code class="language-plaintext highlighter-rouge">site-available/nexus.conf</code> for the Nexus site:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>upstream nexus {
  server        nexus:8081;
}

server {
  listen        443 ssl;
  server_name   opencraft-vm.labs.vu.nl;

  include	common.conf;
  include	/etc/nginx/ssl.conf;

  location / {
    proxy_pass  http://nexus;
    include	common_location.conf;
  }
}
</code></pre></div></div> <p>The <code class="language-plaintext highlighter-rouge">upstream nexus</code> lets NGINX know that it can find a site called <em>nexus</em> at <code class="language-plaintext highlighter-rouge">nexus:8081</code>. The latter <code class="language-plaintext highlighter-rouge">nexus</code> is interpreted as a domain/host name. Docker Compose makes sure NGINX will be able to correctly resolve this name to an address.</p> <p>The <code class="language-plaintext highlighter-rouge">listen</code> and <code class="language-plaintext highlighter-rouge">server_name</code> match incoming requests that should be forwarded to the nexus site.</p> <p>The two included config files are related to HTTPS. <code class="language-plaintext highlighter-rouge">common.conf</code> prevents users from connecting over plain HTTP:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Only allow httpS connections.
add_header Strict-Transport-Security    "max-age=31536000; includeSubDomains" always;
add_header X-Frame-Options              SAMEORIGIN;
# Don't execute (potentially dangerous) files.
add_header X-Content-Type-Options       nosniff;
add_header X-XSS-Protection             "1; mode=block";
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">ssl.conf</code> configures NGINX SSL options:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># These settings configure which ciphers and certificates to use.
ssl_protocols               TLSv1 TLSv1.1 TLSv1.2;
ssl_ecdh_curve              secp384r1;
ssl_ciphers                 "ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-SHA384 OLD_TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256 OLD_TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256";
ssl_prefer_server_ciphers   on;
ssl_session_timeout         10m;
ssl_session_cache           shared:SSL:10m;
ssl_session_tickets         off;

# Point NGINX to the location of certificates.
ssl_certificate /etc/ssl/private/cert-chain.pem;
ssl_certificate_key /etc/ssl/private/key.pem;
ssl_trusted_certificate /etc/ssl/private/chain-root.pem;
ssl_dhparam /etc/ssl/private/dh.pem;
ssl_stapling on;
ssl_stapling_verify on;

resolver 1.1.1.1 1.0.0.1;
</code></pre></div></div> <p>The <code class="language-plaintext highlighter-rouge">location</code> option in <code class="language-plaintext highlighter-rouge">nexus.conf</code> matches the request path that should be forwarded to the nexus site. In this case, we redirect requests on the root path (<code class="language-plaintext highlighter-rouge">/</code>).</p> <p>Finally, we include a <code class="language-plaintext highlighter-rouge">common_path.conf</code> to forward information from the original requester when forwarding requests to the nexus site.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Forward information from request to the service.
# Without these settings, the internal service sees all requests as coming from NGINX.
proxy_set_header    X-Real-IP           $remote_addr;
proxy_set_header    X-Forwarded-For     $proxy_add_x_forwarded_for;
proxy_set_header    X-Forwarded-Proto   $scheme;
proxy_set_header    Host                $host;
proxy_set_header    X-Forwarded-Host    $host;
proxy_set_header    X-Forwarded-Port    $server_port;
</code></pre></div></div> <p>Because NGINX is acting as a reverse proxy, these headers are needed to give Nexus information about where the requests originate from.</p> <p>Finally, we enable the site by creating a symbolic link.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cd sites-enabled
ln -s ../sites-available/nexus.conf .
</code></pre></div></div> <h2 id="docker-compose">Docker Compose</h2> <p>Docker Compose allows us to define an application consisting of multiple services, where each service consists of one or more containers of a certain type. In our case, it allows combining the Nexus and NGINX services in a single app.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>version: '3'

services:
  revproxy:
    container_name: revproxy
    hostname: revproxy
    image: nginx
    restart: always
    ports:
      - 80:80
      - 443:443
    volumes:
      - /path/to/config:/etc/nginx
      - /path/to/keys:/etc/ssl/private
    depends_on:
      - nexus
  nexus:
    container_name: nexus
    hostname: nexus
    image: sonatype/nexus3
    restart: always
    volumes:
      - /path/to/nexus/data:/nexus-data
</code></pre></div></div> <p>This configuration file defines two services: <em>revproxy</em> and <em>nexus</em>. The revproxy service runs an NGINX image, exposes HTTP(S) ports, and mounts two host directories containing the configuration discussed in <a href="#NGINX">the previous section</a>. The nexus service runs a Sonatype Nexus 3, and mounts a host directory containing its data and configuration files.</p> <p>A few things to note:</p> <ol> <li>Because Docker Compose connects all services to a bridge network by default, and the Nexus will only communicate with the NGINX service, the Nexus service does not need to bind ports to the host. This means the Nexus is only accessible via the NGINX reverse proxy, which is exactly what we want.</li> <li>Despite not allowing plain HTTP requests, binding port 80 allows us to redirect users to HTTPS on port 443.</li> <li>The <code class="language-plaintext highlighter-rouge">restart: always</code> rule makes sure the services are restarted after reboots and crashes.</li> <li>All configuration is located in the mounted host directories (under <em>volumes</em>). This means that we can remove and recreate the containers without having to reconfigure them.</li> </ol> <h2 id="starting-the-application">Starting the Application</h2> <p>After performing the configuration in the previous two sections, we start the services by running <code class="language-plaintext highlighter-rouge">docker-compose up -d</code>.</p> <h2 id="configuring-nexus">Configuring Nexus</h2> <p>We configure the Nexus via its web interface, which is now accessible via the browser. Run <code class="language-plaintext highlighter-rouge">docker exec -it nexus cat /nexus-data/admin.password</code>, or look in the <code class="language-plaintext highlighter-rouge">admin.password</code> file in the mounted directory on the host, to obtain the default password. Upon first login, the system will ask for a new password.</p> <p>We can create new artifact repositories by first clicking the gear icon (<img src="/images/gear.png" alt="gear icon"/>) at the top left, followed by repositories (<img src="/images/repositories.png" alt="repositories"/>) in the navigation menu on the left-hand side. Here we create several Maven repositories for Opencraft:</p> <ol> <li>Several <em>proxy</em> repositories, which point to other remote artifact repositories that contain Opencraft dependencies.</li> <li>Two <em>hosted</em> repositories, <code class="language-plaintext highlighter-rouge">opencraft-releases</code> and <code class="language-plaintext highlighter-rouge">opencraft-snapshots</code>, where we publish Opencraft artifacts.</li> <li>One <em>group</em> repository, <code class="language-plaintext highlighter-rouge">opencraft-group</code>, which combines all other repositories and makes them available through a single URL.</li> </ol> <p>The proxy repositories, combined with their caching feature, are what allow us to meet the <a href="#requirements">requirements</a> we formulated at the start of this post. Once we obtain a dependency artifact, we need it to be permanently available (Requirement 1) and prevent it from changing (Requirement 2). However, some of these dependencies are only hosted for a limited amount of time, or are published as snapshots.</p> <p>To solve this, we create a proxy repository for each repository that either hosts dependency artifacts for a limited time, or only makes artifacts available as snapshots. This way, we only download the dependency artifact once, and keep it cached permanently in our own Nexus. To prevent cached artifacts from getting overwritten or removed, we need to set the maximum age of cached artifacts to <code class="language-plaintext highlighter-rouge">-1</code> when creating the proxy repository.</p> <p><img src="/images/maximum-artifact-age.png" alt="maximum artifact age"/></p> <h2 id="maven">Maven</h2> <p>Once the application is running and we have configured our artifact repositories, we can modify our Maven projects to use our Nexus. We do this by adding the following code to our <code class="language-plaintext highlighter-rouge">pom.xml</code>:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;repositories&gt;
    &lt;repository&gt;
        &lt;id&gt;opencraft-group&lt;/id&gt;
        &lt;url&gt;https://opencraft.labs.vu.nl/repository/opencraft-group&lt;/url&gt;
        &lt;releases&gt;
            &lt;enabled&gt;true&lt;/enabled&gt;
        &lt;/releases&gt;
        &lt;snapshots&gt;
            &lt;enabled&gt;true&lt;/enabled&gt;
        &lt;/snapshots&gt;
    &lt;/repository&gt;
&lt;/repositories&gt;

&lt;distributionManagement&gt;
    &lt;repository&gt;
        &lt;id&gt;opencraft-releases&lt;/id&gt;
        &lt;url&gt;https://opencraft-vm.labs.vu.nl/repository/opencraft-releases/&lt;/url&gt;
    &lt;/repository&gt;
    &lt;snapshotRepository&gt;
        &lt;id&gt;opencraft-snapshots&lt;/id&gt;
        &lt;url&gt;https://opencraft-vm.labs.vu.nl/repository/opencraft-snapshots/&lt;/url&gt;
    &lt;/snapshotRepository&gt;
&lt;/distributionManagement&gt;
</code></pre></div></div> <p>The <code class="language-plaintext highlighter-rouge">&lt;repository&gt;</code> tag uses our group repository to let Maven retrieve dependencies through our Nexus. Specifically, it makes Maven look for direct dependencies of our project in the provided repositories. However, these dependencies can specify their own repositories in their own <code class="language-plaintext highlighter-rouge">pom.xml</code> files, which take precedence when downloading <em>their</em> dependencies. To make sure that we recursively cache all dependency artifacts, we need to make the following addition to our <code class="language-plaintext highlighter-rouge">~/.m2/settings.xml</code>:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;mirrors&gt;
	&lt;mirror&gt;
		&lt;id&gt;opencraft-group&lt;/id&gt;
		&lt;url&gt;https://opencraft.labs.vu.nl/repository/opencraft-group&lt;/url&gt;
		&lt;mirrorOf&gt;*&lt;/mirrorOf&gt;
	&lt;/mirror&gt;
&lt;/mirrors&gt;
</code></pre></div></div> <p>This tells Maven that it should use a mirror for all (<code class="language-plaintext highlighter-rouge">*</code>) repositories, available at <code class="language-plaintext highlighter-rouge">https://opencraft.labs.vu.nl/repository/opencraft-group</code>. To make this work, we need to make sure that all dependencies can be retrieved via the group repository by adding all required proxy repositories.</p> <p>An additional benefit of hosting our own artifact repository is the ability to host our own artifacts. We configure this by adding the <code class="language-plaintext highlighter-rouge">&lt;distributionManagement&gt;</code> tag. It instructs Maven to upload our own artifacts to our Nexus when running <code class="language-plaintext highlighter-rouge">mvn deploy</code>.</p> <p>When deploying artifacts to our repository, we need to authenticate ourselves. We do this by adding the following code to <code class="language-plaintext highlighter-rouge">~/.m2/settings.xml</code>:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;settings&gt;
	&lt;servers&gt;
		&lt;server&gt;
			&lt;id&gt;opencraft-releases&lt;/id&gt;
			&lt;username&gt;admin&lt;/username&gt;
			&lt;password&gt;password&lt;/password&gt;
		&lt;/server&gt;
		&lt;server&gt;
			&lt;id&gt;opencraft-snapshots&lt;/id&gt;
			&lt;username&gt;admin&lt;/username&gt;
			&lt;password&gt;password&lt;/password&gt;
		&lt;/server&gt;
	&lt;/servers&gt;
&lt;/settings&gt;
</code></pre></div></div> <p>to avoid using a plain-text password, we can use a <a href="https://maven.apache.org/guides/mini/guide-encryption.html">Maven master password</a>.</p> <h2 id="conclusion">Conclusion</h2> <p>We encountered software build problems because our projects depend on third-party software that exclusively use SNAPSHOT versions and are only temporarily available. This was problematic for our research project, which requires the ability to compile and run code that can be multiple years old. Setting up a Nexus and NGINX remote proxy solves these challenges. Third-party software is now only retrieved once, and then remains permanently cached in our Nexus artifact repository. This allows all Opencraft team members to build and compile code without the risk of dependencies no longer being available. As a bonus, we can use the Nexus to publish our own artifacts, making it easier to share internal dependencies.</p> <hr/> <p><strong>Sources</strong></p> <ol> <li><a href="https://blog.sonatype.com/maxences-technical-corner">https://blog.sonatype.com/maxences-technical-corner</a></li> <li><a href="https://hub.docker.com/r/sonatype/nexus3/">https://hub.docker.com/r/sonatype/nexus3/</a></li> <li><a href="https://stackoverflow.com/questions/36879595/cant-use-nexus-repository-manager-3-0-default-admin-user">https://stackoverflow.com/questions/36879595/cant-use-nexus-repository-manager-3-0-default-admin-user</a></li> <li><a href="https://www.freecodecamp.org/news/docker-nginx-letsencrypt-easy-secure-reverse-proxy-40165ba3aee2/">https://www.freecodecamp.org/news/docker-nginx-letsencrypt-easy-secure-reverse-proxy-40165ba3aee2/</a></li> <li><a href="https://blog.sonatype.com/running-the-nexus-platform-behind-nginx-using-docker">https://blog.sonatype.com/running-the-nexus-platform-behind-nginx-using-docker</a></li> <li><a href="https://stackoverflow.com/questions/36879595/cant-use-nexus-repository-manager-3-0-default-admin-user">https://stackoverflow.com/questions/36879595/cant-use-nexus-repository-manager-3-0-default-admin-user</a></li> <li><a href="https://github.com/030/n3dr">https://github.com/030/n3dr</a></li> <li><a href="https://www.mojohaus.org/versions-maven-plugin/examples/lock-snapshots.html">https://www.mojohaus.org/versions-maven-plugin/examples/lock-snapshots.html</a></li> <li><a href="https://docs.github.com/en/actions/language-and-framework-guides/publishing-java-packages-with-maven">https://docs.github.com/en/actions/language-and-framework-guides/publishing-java-packages-with-maven</a></li> </ol>]]></content><author><name></name></author><category term="software-engineering"/><summary type="html"><![CDATA[After struggling with sharing Maven artifacts for longer than I want to admit, I finally set up a dedicated artifact repository for Opencraft.]]></summary></entry><entry><title type="html">Moving from GitLab to GitHub</title><link href="https://jdonkervliet.github.io/blog/2020/gitlab-to-github/" rel="alternate" type="text/html" title="Moving from GitLab to GitHub"/><published>2020-08-24T00:00:00+00:00</published><updated>2020-08-24T00:00:00+00:00</updated><id>https://jdonkervliet.github.io/blog/2020/gitlab-to-github</id><content type="html" xml:base="https://jdonkervliet.github.io/blog/2020/gitlab-to-github/"><![CDATA[<p>Failing hard drives and general system unavailablity every other week made me migrate more than 30 software repositories to a managed service.</p> <p>For several years, the research group I’m a part of has been using a self-hosted GitLab instance to host their software repositories. There are clear benefits to this approach: no limits on the number of (private) repositories or amount of storage, and full control over the hardware. However, with the hardware underlying our self-hosted instance reaching end-of-life, and limited time for maintenance, it was time to look for another solution. Fortunately, GitHub just expanded the capabilities of their <a href="https://github.blog/2020-04-14-github-is-now-free-for-teams/">free tier</a>. Because we already had several public projects on GitHub, we decided move from our self-hosted GitLab instance to GitHub.</p> <p>Overall, I moved the repositories from GitLab to GitHub in two steps.</p> <ol> <li>Moving 20+ repositories from GitLab to GitHub.</li> <li>Moving issues and merge requests from roughly 3 GitLab repositories to GitHub.</li> </ol> <h1 id="moving-git-repositories-from-gitlab-to-github">Moving Git Repositories from GitLab to GitHub</h1> <p>After migrating the first few repositories by hand,<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> I found out you can import existing repositories quickly using <a href="https://github.com/new/import">GitHub’s import tool</a>. With this tool, you only need to submit a URL pointing to the original repository and the desired name of the new repository.</p> <p><img src="/images/github-import.png" alt="GitHub's Importer"/></p> <p>Unfortunately, I quickly ran into trouble using this method. Most of our GitLab repositories are only visible to registered users. To read the repository, the user needs to log in. Although GitHub’s import tool registered this and asked for my credentials, the result was the following message:</p> <blockquote> <p>No source repositories were detected at &lt;repo_url&gt;. Please check the URL and try again.</p> </blockquote> <p>Because I knew the repo URL to be correct, it took a while before I figured that my two-factor authentication (2FA) was the issue. Thank you, error message!</p> <p>The proper way to solve this, is to create a <code class="language-plaintext highlighter-rouge">read_repository</code> access token, and use that as your password. Instead, I temporarily disabled my 2FA.</p> <h1 id="moving-merge-requests-and-issues-from-gitlab-to-github">Moving Merge Requests and Issues from GitLab to GitHub</h1> <p>Because many repositories belonged to single developers, only a few repositories contained merge requests (and issues). Whereas <a href="https://docs.gitlab.com/ee/user/project/import/github.html">GitLab’s import tool</a> imports a GitHub repository including its pull requests, issues, wikis, and other data, GitHub’s importer only imports the bare-bones Git repository.</p> <p>Because I did not want to lose data, I searched the Internet for third-party tools that can do the job. I quickly found <a href="https://github.com/piceaTech/node-gitlab-2-github">node-gitlab-2-github</a>, which works reasonably well. Among other things, it allows you to import issues and pull requests. It can also map GitLab usernames to GitHub usernames, which prevents @-mentions from breaking. Its README is clear, and the process is straightforward. Get access tokens for both GitLab and GitHub, fill in the <code class="language-plaintext highlighter-rouge">settings.ts</code> file, and let the script do its work.</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1" role="doc-endnote"> <p><code class="language-plaintext highlighter-rouge">git remote add github &lt;repo_url&gt; &amp;&amp; git push --mirror github</code> <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name></name></author><category term="software-engineering"/><summary type="html"><![CDATA[Failing hard drives and general system unavailablity every other week made me migrate more than 30 software repositories to a managed service.]]></summary></entry><entry><title type="html">Teaching Cloud Computing at restart.network</title><link href="https://jdonkervliet.github.io/blog/2017/restart-network-cloud-workshop/" rel="alternate" type="text/html" title="Teaching Cloud Computing at restart.network"/><published>2017-05-09T21:30:57+00:00</published><updated>2017-05-09T21:30:57+00:00</updated><id>https://jdonkervliet.github.io/blog/2017/restart-network-cloud-workshop</id><content type="html" xml:base="https://jdonkervliet.github.io/blog/2017/restart-network-cloud-workshop/"><![CDATA[<p>This week I had a lot of fun teaching the basics of cloud computing at <a href="https://restart.network/">restart.network</a>, a start-up company that offers computer-science bootcamps to refugees, helping them get into the Dutch job-market.</p> <blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Jesse Donkervliet <a href="https://twitter.com/LargeResearch">@LargeResearch</a> (<a href="https://twitter.com/EEMCS_TUD">@EEMCS_TUD</a>) introduces the dual scheduling problem of cloud computing to the <a href="https://twitter.com/Restart_Network">@Restart_Network</a> students. <a href="https://t.co/WY353u4ilF">pic.twitter.com/WY353u4ilF</a></p>&mdash; Alexandru Iosup (@AIosup) <a href="https://twitter.com/AIosup/status/859054233588559872">May 1, 2017</a></blockquote> <script async="" src="//platform.twitter.com/widgets.js" charset="utf-8"></script> <p>The goal of the session is to let students understand what it means to run a program <em>in the cloud</em>, and is part of a larger one-day cloud-computing workshop and follows an introductory lecture. Where is the cloud located? How can I put stuff on the cloud? How do I interact with my programs once they are running? These are some of the questions students get to answer during the workshop.</p> <p>During roughly 1.5 hours, students go through the steps of manually selecting and booting their own <em>virtual machine</em> in the cloud, and using it run a web-server and do some basic image processing. At the end of the session students no longer view <em>the cloud</em> as a magical place, but understand the basic concepts about the hardware and software that makes this multi-billion dollar industry work.</p>]]></content><author><name></name></author><category term="education"/><summary type="html"><![CDATA[This week I had a lot of fun teaching the basics of cloud computing at restart.network, a start-up company that offers computer-science bootcamps to refugees, helping them get into the Dutch job-market.]]></summary></entry></feed>